{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b0d2cec",
   "metadata": {},
   "source": [
    "# Update Silver Layer\n",
    "This notebook reads the bronze Delta tables and writes cleaned data to the `silver` schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf895091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, from_json\n",
    "from pyspark.sql.types import IntegerType, DoubleType, MapType, StringType\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create silver database if not exists\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS silver\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa82163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Customers table\n",
    "df_customers = spark.table('bronze.customers')    .withColumn('became_member_on', to_date(col('became_member_on')))    .withColumn('age', col('age').cast(IntegerType()))    .withColumn('income', col('income').cast(DoubleType()))\n",
    "\n",
    "df_customers.write.mode('overwrite').format('delta').saveAsTable('silver.customers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Offers table\n",
    "df_offers = spark.table('bronze.offers')    .withColumn('difficulty', col('difficulty').cast(IntegerType()))    .withColumn('reward', col('reward').cast(IntegerType()))    .withColumn('duration', col('duration').cast(IntegerType()))\n",
    "\n",
    "df_offers.write.mode('overwrite').format('delta').saveAsTable('silver.offers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7713c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Events table\n",
    "schema = MapType(StringType(), StringType())\n",
    "df_events = spark.table('bronze.events')    .withColumn('time', col('time').cast(IntegerType()))    .withColumn('value', from_json(col('value'), schema))\n",
    "\n",
    "df_events.write.mode('overwrite').format('delta').saveAsTable('silver.events')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
